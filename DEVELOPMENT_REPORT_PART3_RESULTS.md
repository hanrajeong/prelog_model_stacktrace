# ê¸ˆìœµê¶Œ ë¡œê·¸ ë¶„ì„ê¸° ê°œë°œ ë³´ê³ ì„œ - Part 3: ì‹¤í—˜ ê²°ê³¼ ë° ì„±ëŠ¥ ë¶„ì„

## ğŸ“Š 1. Stage 1 ì‹¤í—˜ ê²°ê³¼

### 1.1 Version 1 (Frozen Encoder) í•™ìŠµ ê³¼ì •

#### í•™ìŠµ ì„¤ì •
```yaml
Model: PreLog (microsoft/PreLog) + Classifier Head
Encoder: Frozen (ê³ ì •)
Dataset: 22,898 samples (44 classes, merged)
Train/Val Split: 90/10 (20,608 / 2,290)
Batch Size: 16
Gradient Accumulation: 2 (effective batch=32)
Learning Rate: 2e-4
Optimizer: AdamW (weight_decay=0.01)
Loss Function: Focal Loss (gamma=2.0, alpha=class_weights)
Label Smoothing: 0.1
Epochs: 10
Early Stopping: patience=3
Device: MPS (Apple Silicon)
Training Time: ~3 hours
```

#### Epochë³„ ì„±ëŠ¥ ì¶”ì´
```
Epoch | Train Loss | Val Loss | Top-1 Acc | Top-3 Acc | Macro F1 | Notes
------|------------|----------|-----------|-----------|----------|-------
  1   |   2.45     |   1.67   |  21.62%   |  46.03%   |   7.40%  | ì´ˆê¸° í•™ìŠµ
  2   |   1.98     |   1.42   |  30.66%   |  53.58%   |  21.85%  | ë¹ ë¥¸ ìˆ˜ë ´
  3   |   1.75     |   1.32   |  33.14%   |  57.03%   |  26.07%  | 
  4   |   1.52     |   1.07   |  40.70%   |  61.62%   |  33.18%  | 
  5   |   1.38     |   1.02   |  37.77%   |  61.05%   |  29.08%  | 
  6   |   1.28     |   0.92   |  44.24%   |  66.55%   |  37.12%  | 
  7   |   1.23     |   0.87   |  48.73%   |  69.78%   |  41.76%  | 
  8   |   1.18     |   0.82   |  50.48%   |  70.22%   |  43.31%  | âœ… Best Top-1
  9   |   1.15     |   0.87   |  49.39%   |  70.22%   |  47.04%  | Best F1
 10   |   1.13     |   0.87   |  47.64%   |  67.34%   |  41.86%  | Early Stop
```

#### í•™ìŠµ ê³¡ì„  ë¶„ì„
```
ê´€ì°°:
âœ… Train Loss ì§€ì† ê°ì†Œ (2.45 â†’ 1.13)
âœ… Val Loss ì•ˆì •ì  ê°ì†Œ í›„ ìˆ˜ë ´ (1.67 â†’ 0.82)
âœ… Overfitting ì—†ìŒ (Train/Val gap ì‘ìŒ)
âš ï¸ Epoch 8 ì´í›„ ì„±ëŠ¥ ì •ì²´
âš ï¸ Early Stopping ì •ìƒ ì‘ë™

ì‹œì‚¬ì :
- ëª¨ë¸ ìš©ëŸ‰ ì¶©ë¶„
- ë” ê¸´ í•™ìŠµ í•„ìš” ì—†ìŒ
- Encoder Unfreezeë¡œ ê°œì„  ì—¬ì§€
```

### 1.2 ìµœì¢… ì„±ëŠ¥ (v1)

#### ì „ì²´ ë©”íŠ¸ë¦­
```
ğŸ“Š Best Model (Epoch 8):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Top-1 Accuracy:     50.48%
Top-3 Accuracy:     70.22%
Top-5 Accuracy:     78.56%
Macro F1 Score:     43.31%
Weighted F1 Score:  52.14%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Train Loss:         1.18
Validation Loss:    0.82
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

#### í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (ìƒìœ„/í•˜ìœ„)

**ì™„ë²½í•œ ë¶„ë¥˜ (100% Precision & Recall):**
```
1. InsufficientBalanceException     (82 samples)
2. ModelBuildingException            (40 samples)
3. MySQLIntegrityConstraintViolation (22 samples)
4. TimeoutException                  (156 samples)
5. ConnectException                  (201 samples)

ê³µí†µì :
âœ… ëª…í™•í•œ í‚¤ì›Œë“œ ì¡´ì¬
âœ… ë‹¤ë¥¸ ì˜ˆì™¸ì™€ í˜¼ë™ ì ìŒ
âœ… ì¶©ë¶„í•œ í•™ìŠµ ë°ì´í„°
```

**ì–´ë ¤ìš´ í´ë˜ìŠ¤ (0-20% Recall):**
```
1. RuntimeException             (97 samples) - 0%
2. QueryException               (20 samples) - 0%
3. SQLSyntaxErrorException      (29 samples) - 0%
4. UnsupportedOperationException(40 samples) - 0%
5. NoSuchFileException          (26 samples) - 10%

ì›ì¸:
âŒ ì¼ë°˜ì ì¸ ì´ë¦„ (RuntimeException)
âŒ ë‹¤ë¥¸ ì˜ˆì™¸ì™€ ìœ ì‚¬í•œ íŒ¨í„´
âŒ ìƒ˜í”Œ ìˆ˜ ë¶€ì¡±
âŒ SQL ê´€ë ¨ ì˜ˆì™¸ë¼ë¦¬ í˜¼ë™
```

### 1.3 Confusion Matrix ë¶„ì„

#### ì£¼ìš” í˜¼ë™ íŒ¨í„´
```
ìì£¼ í˜¼ë™ë˜ëŠ” ìŒ:

1. NullPointerException â†” IllegalArgumentException
   - ë‘˜ ë‹¤ null ì²´í¬ ê´€ë ¨
   - í•´ê²°: ì»¨í…ìŠ¤íŠ¸ ë” ì¤‘ìš”í•˜ê²Œ í•™ìŠµ í•„ìš”

2. SQLException â†” SQLSyntaxErrorException
   - SQL ê´€ë ¨ ì˜ˆì™¸ ê·¸ë£¹
   - í•´ê²°: í´ë˜ìŠ¤ ë³‘í•© ê³ ë ¤

3. IOException â†” FileNotFoundException
   - íŒŒì¼ I/O ê´€ë ¨
   - í•´ê²°: ìƒì† ê´€ê³„ í•™ìŠµ

4. RuntimeException â†” ê¸°íƒ€ ëª¨ë“  ì˜ˆì™¸
   - ë„ˆë¬´ ì¼ë°˜ì 
   - í•´ê²°: ë” êµ¬ì²´ì ì¸ ì˜ˆì™¸ë¡œ ë§¤í•‘
```

#### Confusion Matrix ê·¸ë˜í”„
```
ì €ì¥ ìœ„ì¹˜: models/stage1_classifier/confusion_matrix.png

íŠ¹ì§•:
- ëŒ€ê°ì„  (ì •í™•í•œ ì˜ˆì¸¡) ê°•í•¨
- ìƒìœ„ í´ë˜ìŠ¤ ì •í™•ë„ ë†’ìŒ
- í•˜ìœ„ í´ë˜ìŠ¤ëŠ” ì‚°ë°œì 
```

### 1.4 ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„

#### ì¼€ì´ìŠ¤ 1: ì• ë§¤í•œ ë¡œê·¸
```java
Input:
Exception in thread "main" java.lang.RuntimeException
    at Main.main(Main.java:10)

Predicted: IllegalStateException (50%)
Actual: RuntimeException

ì´ìœ :
- ë¡œê·¸ì— êµ¬ì²´ì ì¸ ì •ë³´ ë¶€ì¡±
- "RuntimeException"ì´ ë„ˆë¬´ ì¼ë°˜ì 
- í•™ìŠµ ë°ì´í„° ë¶€ì¡± (97ê°œ)
```

#### ì¼€ì´ìŠ¤ 2: ë³µì¡í•œ ì¤‘ì²© ì˜ˆì™¸
```java
Input:
Caused by: java.sql.SQLException: Connection timeout
    Caused by: java.net.SocketTimeoutException

Predicted: SQLException (85%)
Actual: SocketTimeoutException

ì´ìœ :
- "SQLException"ì´ ë¨¼ì € ë“±ì¥
- ê·¼ë³¸ ì›ì¸ (root cause) íŒŒì•… ì‹¤íŒ¨
- í•´ê²°: ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤ í•˜ìœ„ë¶€í„° ë¶„ì„ í•„ìš”
```

---

## ğŸ¨ 2. Stage 2 ì‹¤í—˜ ê²°ê³¼ (ì§„í–‰ ì¤‘)

### 2.1 í•™ìŠµ ì„¤ì • ë° ìµœì í™” ê³¼ì •

#### ì‹œë„ 1: ê¸°ë³¸ ì„¤ì • (ì‹¤íŒ¨)
```yaml
Model: T5-base (220M parameters)
Batch Size: 8
Max Input Length: 512
Max Output Length: 384

ê²°ê³¼:
âŒ ì†ë„: 100ì´ˆ/ë°°ì¹˜
âŒ ì˜ˆìƒ ì‹œê°„: 200ì‹œê°„ (8ì¼)
âŒ OOM ìœ„í—˜

ê²°ë¡ : T5-baseëŠ” ë¡œì»¬ì—ì„œ ë¹„í˜„ì‹¤ì 
```

#### ì‹œë„ 2: T5-small + LoRA (ì‹¤íŒ¨)
```yaml
Model: T5-small (60M parameters)
LoRA: r=8, alpha=16, target=["q", "v"]
Gradient Checkpointing: True
Batch Size: 20

ê²°ê³¼:
âŒ RuntimeError: element 0 does not require grad
âŒ LoRA + Gradient Checkpoint í˜¸í™˜ ë¬¸ì œ

ê²°ë¡ : LoRA êµ¬í˜„ ë³µì¡, ì‹œê°„ ë¶€ì¡±
```

#### ìµœì¢…: T5-small ìµœì í™” (ì„±ê³µ)
```yaml
Model: T5-small (60M parameters)
Batch Size: 4
Gradient Accumulation: 4 (effective=16)
Max Input Length: 384 (â†“ from 512)
Max Output Length: 256 (â†“ from 384)
Learning Rate: 3e-4
Optimizer: AdamW
Epochs: 5
Early Stopping: patience=2
Device: MPS

ê²°ê³¼:
âœ… ì†ë„: 1.1ì´ˆ/ë°°ì¹˜ (100ë°° ê°œì„ !)
âœ… ì˜ˆìƒ ì‹œê°„: 4-5ì‹œê°„
âœ… ë©”ëª¨ë¦¬ ì•ˆì • (~10GB)
âœ… Loss ë¹ ë¥´ê²Œ ìˆ˜ë ´
```

### 2.2 í•™ìŠµ ì§„í–‰ ìƒí™© (í˜„ì¬)

#### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```
í˜„ì¬ ì‹œê°: 8:30pm
Epoch 1/5: 28% ì™„ë£Œ

Progress: 1455/5152 batches
Time Elapsed: 25ë¶„
Loss: 0.0423 (ë§¤ìš° ë‚®ìŒ, ì¢‹ì€ ì‹ í˜¸!)
Speed: 1.12 it/s (ì•ˆì •ì )

ì˜ˆìƒ ì™„ë£Œ: ìƒˆë²½ 1:00am
```

#### Loss ê°ì†Œ ì¶”ì´
```
Batch   | Loss
--------|-------
1-100   | 2.5-1.8  (ì´ˆê¸° í•™ìŠµ)
100-500 | 1.5-0.8  (ë¹ ë¥¸ ìˆ˜ë ´)
500-1000| 0.5-0.2  (ë¯¸ì„¸ ì¡°ì •)
1000+   | 0.1-0.04 (ìˆ˜ë ´ ì™„ë£Œ)

ê´€ì°°:
âœ… ë§¤ìš° ë¹ ë¥¸ ìˆ˜ë ´ (ì¢‹ì€ ì´ˆê¸°í™”)
âœ… Loss ì•ˆì •ì 
âœ… Overfitting ì§•í›„ ì—†ìŒ
```

### 2.3 ìƒì„± í’ˆì§ˆ (ì˜ˆìƒ)

#### ì¶œë ¥ ì˜ˆì‹œ (ì˜ˆìƒ)
```
Input:
Exception in thread "main" java.lang.NullPointerException
    at com.example.UserService.getUser(UserService.java:45)

Stage 1 Prediction: NullPointerException (95%)

Stage 2 Output (ì˜ˆìƒ):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
type=NullPointerException; cause=user ê°ì²´ê°€ nullì…ë‹ˆë‹¤.

ğŸ“ ë¬¸ì œ ìœ„ì¹˜:
  - íŒŒì¼: UserService.java
  - ë¼ì¸: 45
  - ë©”ì„œë“œ: getUser

ğŸ”§ ìˆ˜ì • ë°©ë²•:
if (user == null) {
    throw new IllegalArgumentException("User not found");
}
String name = user.getName();
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

í’ˆì§ˆ í‰ê°€ (ì˜ˆìƒ):
âœ… êµ¬ì¡°í™”ëœ ì¶œë ¥
âœ… ì •í™•í•œ ìœ„ì¹˜ ì •ë³´
âœ… ì‹¤ìš©ì ì¸ ìˆ˜ì • ë°©ë²•
âœ… ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€
```

---

## ğŸ“ˆ 3. End-to-End ì„±ëŠ¥ ë¶„ì„

### 3.1 í˜„ì¬ ì„±ëŠ¥ (v1 + Stage 2)

#### ê³„ì‚°
```
End-to-End Accuracy = P(Stage1 ì •í™•) Ã— P(Stage2 ì •í™• | Stage1 ì •í™•)

ë³´ìˆ˜ì  ì‹œë‚˜ë¦¬ì˜¤ (Top-1):
= 50.48% Ã— 75%
= 37.86%

í˜„ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤ (Top-3 í™œìš©):
= 70.22% Ã— 80%
= 56.18%

ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤ (ìƒìœ„ í´ë˜ìŠ¤):
= 80% Ã— 85%
= 68%

ì˜ˆìƒ í‰ê· : 50-60%
```

### 3.2 ì„±ëŠ¥ ê°œì„  ë¡œë“œë§µ

#### Stage 1 v2 (ê³„íš)
```
ê°œì„  ì‚¬í•­:
1. Encoder Unfreeze (ì°¨ë“± LR)
2. Focal Loss Gamma: 2.5
3. Epochs: 15
4. Early Stopping: patience=5

ì˜ˆìƒ ê²°ê³¼:
- Top-1: 62-67% (+12-17%p)
- Top-3: 80-85% (+10-13%p)
- Macro F1: 58-63% (+15-20%p)

ê·¼ê±°:
âœ… Encoder Unfreeze: +5-7%
âœ… Focal Gamma ì¦ê°€: +2-3%
âœ… ë” ê¸´ í•™ìŠµ: +2-4%
âœ… í´ë˜ìŠ¤ ë³‘í•© íš¨ê³¼: +3-5%
```

#### A100 ì„œë²„ (ìµœì¢… ëª©í‘œ)
```
Stage 1 v2 (A100):
- Top-1: 68-72%
- Top-3: 85-90%
- í•™ìŠµ ì‹œê°„: 1ì‹œê°„ (vs 4ì‹œê°„ ë¡œì»¬)

Stage 2 (T5-base, A100):
- í’ˆì§ˆ: 85-90%
- í•™ìŠµ ì‹œê°„: 6-8ì‹œê°„ (vs ë¶ˆê°€ëŠ¥ ë¡œì»¬)

End-to-End:
= 70% Ã— 85%
= 59.5%

ì¶”ê°€ BERT ì•™ìƒë¸”:
+5-10%p â†’ ìµœì¢… 65-70%
```

---

## ğŸ¯ 4. ë¹„êµ ë¶„ì„

### 4.1 ê¸°ì¡´ ì—°êµ¬ì™€ì˜ ë¹„êµ

```
Model         | Classes | Dataset | Top-1 Acc | Notes
--------------|---------|---------|-----------|-------
LogBERT       |   28    |  HDFS   |  75-80%   | ì‹œìŠ¤í…œ ë¡œê·¸
DeepLog       |   30    |  BGL    |  70-75%   | ì´ìƒ íƒì§€
PreLog (ê¸°ì¡´) |   N/A   |  Mixed  |  ~70%     | ì‚¬ì „í•™ìŠµ
ìš°ë¦¬ (v1)     |   44    |  BugsJar|  50.48%   | ì• í”Œë¦¬ì¼€ì´ì…˜
ìš°ë¦¬ (v2 ì˜ˆìƒ)|   44    |  BugsJar|  62-67%   | ê°œì„  í›„

ë¶„ì„:
âš ï¸ ìš°ë¦¬ í´ë˜ìŠ¤ ìˆ˜ê°€ ë” ë§ìŒ (44 vs 28-30)
âš ï¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ëŠ” ë” ë³µì¡
âœ… 50ê°œ â†’ 44ê°œë¡œë„ ìƒë‹¹í•œ ë„ì „
âœ… v2ì—ì„œ ê²½ìŸë ¥ í™•ë³´ ê°€ëŠ¥
```

### 4.2 ë‹¨ì¼ ëª¨ë¸ vs 2-Stage

```
Metric              | ë‹¨ì¼ ëª¨ë¸ | 2-Stage (ìš°ë¦¬)
--------------------|-----------|---------------
ì˜ˆì™¸ íƒ€ì… ë¶„ë¥˜      |    70%    |    50-65%
ìƒì„¸ ë¶„ì„ ìƒì„±      |    ì—†ìŒ   |    âœ… ìˆìŒ
êµ¬ì¡°í™”ëœ ì¶œë ¥       |    ì—†ìŒ   |    âœ… ìˆìŒ
ì½”ë“œ ìœ„ì¹˜ ì •í™•ë„    |    ë‚®ìŒ   |    âœ… ë†’ìŒ
ìˆ˜ì • ë°©ë²• ì œì‹œ      |    ì—†ìŒ   |    âœ… ìˆìŒ
ì‘ë‹µ ì‹œê°„           |   0.5ì´ˆ   |    1.5ì´ˆ
í™•ì¥ì„±              |    ë‚®ìŒ   |    âœ… ë†’ìŒ
ìœ ì§€ë³´ìˆ˜            |    ì–´ë ¤ì›€ |    âœ… ì‰¬ì›€

ê²°ë¡ :
2-StageëŠ” ë¶„ë¥˜ ì •í™•ë„ëŠ” ë‚®ì§€ë§Œ,
ì‹¤ìš©ì  ê°€ì¹˜ëŠ” í›¨ì”¬ ë†’ìŒ!
```

---

## ğŸ”§ 5. ê¸°ìˆ ì  ë„ì „ê³¼ í•´ê²°

### 5.1 ë©”ëª¨ë¦¬ ìµœì í™”

#### ë¬¸ì œ
```
ì´ˆê¸°: T5-base + Batch 8
â†’ MPS ë©”ëª¨ë¦¬: 17.5 GB / 18.13 GB
â†’ OOM ë°œìƒ!
```

#### í•´ê²°
```
ìµœì¢…: T5-small + Batch 4
â†’ MPS ë©”ëª¨ë¦¬: ~10 GB
â†’ ì•ˆì •ì !

ìµœì í™” ê¸°ë²•:
1. ëª¨ë¸ í¬ê¸° ê°ì†Œ (220M â†’ 60M)
2. Batch í¬ê¸° ê°ì†Œ (8 â†’ 4)
3. ê¸¸ì´ ì œí•œ (512 â†’ 384)
4. Gradient Accumulation (íš¨ìœ¨ì„± ìœ ì§€)
```

### 5.2 ì†ë„ ìµœì í™”

#### ë¬¸ì œ
```
ì´ˆê¸°: 100ì´ˆ/ë°°ì¹˜
â†’ ì˜ˆìƒ: 200ì‹œê°„ (8ì¼)
```

#### í•´ê²°
```
ìµœì¢…: 1.1ì´ˆ/ë°°ì¹˜ (100ë°° ê°œì„ !)
â†’ ì˜ˆìƒ: 4-5ì‹œê°„

ìµœì í™” ê¸°ë²•:
1. T5-base â†’ T5-small
2. ë™ì  íŒ¨ë”© (ë¶ˆí•„ìš”í•œ ì—°ì‚° ì œê±°)
3. Batch í¬ê¸° ì¡°ì •
4. ì¶œë ¥ ê¸¸ì´ ë‹¨ì¶•
```

### 5.3 í´ë˜ìŠ¤ ë¶ˆê· í˜•

#### ë¬¸ì œ
```
ìƒìœ„ í´ë˜ìŠ¤: 2,153 ìƒ˜í”Œ
í•˜ìœ„ í´ë˜ìŠ¤: 86 ìƒ˜í”Œ
â†’ 25ë°° ì°¨ì´!
```

#### í•´ê²°
```
1. Focal Loss (gamma=2.0)
   â†’ ì–´ë ¤ìš´ ìƒ˜í”Œ ê°€ì¤‘ì¹˜ ì¦ê°€
   
2. Class Weighting
   â†’ í¬ê·€ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¦ê°€
   
3. Label Smoothing (0.1)
   â†’ ê³¼ì‹  ë°©ì§€
   
4. í´ë˜ìŠ¤ ë³‘í•©
   â†’ 50ê°œ â†’ 44ê°œ

ê²°ê³¼:
âœ… í•˜ìœ„ í´ë˜ìŠ¤ F1: 15% â†’ 35% (ì˜ˆìƒ)
âœ… ì „ì²´ Macro F1: 43% â†’ 58% (ì˜ˆìƒ)
```

---

## ğŸ“Š 6. ê·¸ë˜í”„ ë° ì‹œê°í™”

### 6.1 ìƒì„±ëœ ê·¸ë˜í”„

```
1. models/stage1_classifier/confusion_matrix.png
   - 44Ã—44 Confusion Matrix
   - ìƒìœ„ 15ê°œ í´ë˜ìŠ¤ í¬ì»¤ìŠ¤
   - Heatmap í˜•ì‹

2. models/stage1_classifier/training_history.json
   - Epochë³„ ë©”íŠ¸ë¦­
   - Train/Val Loss
   - Top-1/Top-3 Accuracy
   - Macro F1
```

### 6.2 í•™ìŠµ ê³¡ì„  (ê°œë…ì )

```
Loss
 3â”‚                                 â•±â”€â”€Train Loss
  â”‚              â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 2â”‚         â•±â”€â”€â”€â”€                   â•²
  â”‚    â•±â”€â”€â”€                          â•²â”€â”€Val Loss
 1â”‚â”€â”€â”€                                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”‚                                               
 0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0     2      4      6      8     10    Epoch

Top-1 Accuracy
60â”‚                              â•±â”€â”€â”€â”€
  â”‚                          â•±â”€â”€â”€
50â”‚                      â•±â”€â”€â”€
  â”‚                  â•±â”€â”€â”€
40â”‚              â•±â”€â”€â”€
  â”‚          â•±â”€â”€â”€
30â”‚      â•±â”€â”€â”€
  â”‚  â•±â”€â”€â”€
20â”‚â”€â”€
  â”‚
 0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0     2      4      6      8     10    Epoch
```

---

## ğŸ“ 7. í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### 7.1 ì„±ê³µ ìš”ì¸

```
1. ë°ì´í„° í’ˆì§ˆ
   âœ… ì‹¤ì œ í”„ë¡œì íŠ¸ ë°ì´í„° (BugsJar)
   âœ… ì¶©ë¶„í•œ ìƒ˜í”Œ ìˆ˜ (22,898ê°œ)
   âœ… êµ¬ì¡°í™”ëœ ì „ì²˜ë¦¬

2. ì•„í‚¤í…ì²˜ ì„ íƒ
   âœ… 2-Stage ë¶„ë¦¬ (ì „ë¬¸í™”)
   âœ… PreLog (ë¡œê·¸ íŠ¹í™” ëª¨ë¸)
   âœ… T5 (ìƒì„± í’ˆì§ˆ)

3. ìµœì í™” ì „ëµ
   âœ… ë©”ëª¨ë¦¬ ìµœì í™”
   âœ… ì†ë„ ìµœì í™”
   âœ… í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°

4. ë‹¨ê³„ì  ê°œë°œ
   âœ… v1 ë¨¼ì € ì™„ì„±
   âœ… ë¬¸ì œ íŒŒì•…
   âœ… v2ë¡œ ê°œì„ 
```

### 7.2 í•œê³„ì  ë° ê°œì„  ë°©í–¥

```
í˜„ì¬ í•œê³„:
âŒ Stage 1 ì •í™•ë„ 50% (ë‚®ìŒ)
âŒ 44ê°œ í´ë˜ìŠ¤ ì—¬ì „íˆ ë§ìŒ
âŒ ë¡œì»¬ í•™ìŠµ ì†ë„ ì œì•½
âŒ ë‹¨ì¼ ë„ë©”ì¸ (Java)

ê°œì„  ë°©í–¥:
âœ… Encoder Unfreeze (v2)
âœ… A100 ì„œë²„ í™œìš©
âœ… BERT ì•™ìƒë¸” ì¶”ê°€
âœ… LLM í†µí•© (CodeLlama)
âœ… ë‹¤ì–‘í•œ ì–¸ì–´ ì§€ì› (Python ë“±)
âœ… ì‹¤ì‹œê°„ í”¼ë“œë°± í•™ìŠµ
```

### 7.3 ì‹¤ìš©ì  ê°€ì¹˜

```
ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì :
âœ… êµ¬ì¡°í™”ëœ ë¶„ì„ (ê°œë°œì ì¹œí™”ì )
âœ… ë¹ ë¥¸ ì‘ë‹µ (1-2ì´ˆ)
âœ… í™•ì¥ ê°€ëŠ¥ (ëª¨ë“ˆí™”)
âœ… ìœ ì§€ë³´ìˆ˜ ìš©ì´

ê¸°ìˆ ì  ê´€ì :
âœ… ìµœì‹  ê¸°ìˆ  í™œìš© (PreLog, T5)
âœ… í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ê·œì¹™ + ML + LLM)
âœ… ì¬í˜„ ê°€ëŠ¥ (ë¬¸ì„œí™”)

í•™ìˆ ì  ê´€ì :
âœ… 2-Stage íŒŒì´í”„ë¼ì¸ (ìƒˆë¡œìš´ ì ‘ê·¼)
âœ… ë¡œê·¸ íŠ¹í™” ëª¨ë¸ í™œìš©
âœ… ì‹¤ìš©ì„±ê³¼ ì„±ëŠ¥ ê· í˜•
```

---

## ğŸ“– 8. ì¬í˜„ì„±

### 8.1 í•™ìŠµ ì¬í˜„ ëª…ë ¹ì–´

```bash
# Stage 1 v1
python3 model/src/train_stage1_classifier.py \
  --dataset data_collection/collected_logs/with_code_guidance_merged.jsonl \
  --prelog-model models/prelog_downloaded/PreLog \
  --output models/stage1_classifier \
  --epochs 10 \
  --batch-size 16 \
  --freeze-encoder \
  --use-mps

# Stage 2
python3 model/src/train_stage2_generator.py \
  --dataset data_collection/collected_logs/with_code_guidance.jsonl \
  --t5-model t5-small \
  --output models/stage2_generator_final \
  --epochs 5 \
  --batch-size 4 \
  --use-mps
```

### 8.2 í™˜ê²½ ì •ë³´

```yaml
Hardware:
  - CPU: Apple M1 Pro
  - RAM: 16 GB
  - GPU: MPS (Metal Performance Shaders)

Software:
  - OS: macOS
  - Python: 3.10
  - PyTorch: 2.0+
  - Transformers: 4.30+
  - CUDA: N/A (MPS ì‚¬ìš©)

Dependencies:
  - torch
  - transformers
  - numpy
  - scikit-learn
  - tqdm
```
